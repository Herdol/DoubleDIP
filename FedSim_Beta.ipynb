{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FedSimv06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOGx9bViqpXPHeYxr+Eq6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Herdol/DoubleDIP/blob/master/FedSim_Beta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AWqenWZTU-l"
      },
      "source": [
        "# Federated Learning Notebook\n",
        "## 1. Installing Necessary Packages\n",
        "Since colab works on remote virtual machine it requires to install packages everytime after disconnection from remote server. \n",
        "\n",
        "\n",
        "Local runtime can prevent this situation. However it will run this code locally and will depend on the local machine harware. \n",
        "\n",
        "---\n",
        "\n",
        "Installation of \"*tensorflow_federated*\" wasn't added in example. However if it is not installed, it causes errors in further cells.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwweGSY5IGLq",
        "outputId": "e73b8423-2960-4f90-d958-36aeda10dac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow_federated_nightly\n",
        "!pip install --quiet --upgrade nest_asyncio\n",
        "!pip install tensorflow_federated\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 522kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 10.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 394.3MB 42kB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 52.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 39.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 38.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 47.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.6MB 47.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 43.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 45.5MB/s \n",
            "\u001b[?25h  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tf-nightly 2.4.0.dev20201022 has requirement absl-py~=0.10, but you'll have absl-py 0.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tf-nightly 2.4.0.dev20201022 has requirement grpcio~=1.32.0, but you'll have grpcio 1.29.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tf-nightly 2.4.0.dev20201022 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "Collecting tensorflow_federated\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/9c/714bf7267b8720a748e584dfc9911f40c2ea3a7fd4934170093c0b1f2a56/tensorflow_federated-0.16.1-py2.py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (0.1.5)\n",
            "Collecting tensorflow-model-optimization~=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7e/e94aa029999ec30951e8129fa992fecbbaffda66eba97c65d5a83f8ea96d/tensorflow_model_optimization-0.3.0-py2.py3-none-any.whl (165kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs~=19.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (19.3.0)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (1.3.1)\n",
            "Collecting tensorflow-addons~=0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/ce/ed8472bf2b93b53702f28d91caee52181f7a10bee6eec0617a71dea12fa6/tensorflow_addons-0.10.0-cp36-cp36m-manylinux2010_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 13.7MB/s \n",
            "\u001b[?25hCollecting tensorflow-privacy~=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/ea/daaecb29276aaf9d051c96a796e0c1809158751231e541509413266d1a57/tensorflow_privacy-0.4.0-py3-none-any.whl (117kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 20.9MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/e3/663eac537202dee730ad6e61769fc3ebce92a6085dbfd13ca902df5f1477/tensorflow-2.2.1-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 18kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio~=1.29.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (1.29.0)\n",
            "Requirement already satisfied: semantic-version~=2.8.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (2.8.5)\n",
            "Requirement already satisfied: cachetools~=3.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (3.1.1)\n",
            "Requirement already satisfied: retrying~=1.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (1.3.3)\n",
            "Requirement already satisfied: absl-py~=0.9.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (0.9.0)\n",
            "Requirement already satisfied: numpy~=1.18.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (1.18.5)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from dm-tree~=0.1.1->tensorflow_federated) (1.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons~=0.10.0->tensorflow_federated) (2.7.1)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.4.0->tensorflow_federated) (1.4.1)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.4.0->tensorflow_federated) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (0.35.1)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (3.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tensorflow_federated) (1.12.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (1.17.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (2020.6.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tensorflow_federated) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow-federated-nightly 0.16.1.dev20201022 has requirement tensorflow-model-optimization~=0.4.0, but you'll have tensorflow-model-optimization 0.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated-nightly 0.16.1.dev20201022 has requirement tensorflow-privacy~=0.5.0, but you'll have tensorflow-privacy 0.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-model-optimization, tensorflow-addons, tensorflow-privacy, tensorflow-estimator, tensorboard, tensorflow, tensorflow-federated\n",
            "  Found existing installation: tensorflow-model-optimization 0.4.1\n",
            "    Uninstalling tensorflow-model-optimization-0.4.1:\n",
            "      Successfully uninstalled tensorflow-model-optimization-0.4.1\n",
            "  Found existing installation: tensorflow-addons 0.8.3\n",
            "    Uninstalling tensorflow-addons-0.8.3:\n",
            "      Successfully uninstalled tensorflow-addons-0.8.3\n",
            "  Found existing installation: tensorflow-privacy 0.5.1\n",
            "    Uninstalling tensorflow-privacy-0.5.1:\n",
            "      Successfully uninstalled tensorflow-privacy-0.5.1\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorboard-2.2.2 tensorflow-2.2.1 tensorflow-addons-0.10.0 tensorflow-estimator-2.2.0 tensorflow-federated-0.16.1 tensorflow-model-optimization-0.3.0 tensorflow-privacy-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGUqBkhVifh0"
      },
      "source": [
        "!pip uninstall -q tensorboard tb-nightly\n",
        "!pip install -q tb-nightly  # or tensorboard, but not both"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UMm1x8Tc6rJ"
      },
      "source": [
        "This cell allows the tensorboard dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KcvDEhEUD3w"
      },
      "source": [
        "## 2. Importing of libraries\n",
        "\n",
        "If output is ```b'Hello World! ```, then everything (at least a lot of thing) is working fine. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYPAQ1lpGMFZ",
        "outputId": "930a6d5b-d2c8-4ef4-95ae-13ecbf4baeeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Hello, World!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSAgGWrkW7BS"
      },
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j6QNUCpyaxr"
      },
      "source": [
        "## 3. Data Distribution\n",
        "In this cell data is distributed among the clients and number of examples are shown in graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwF0nO3vXXSc"
      },
      "source": [
        "# Number of examples per layer for a sample of clients\n",
        "from matplotlib import pyplot as plt\n",
        "f = plt.figure(figsize=(12, 7))\n",
        "f.suptitle('Label Counts for a Sample of Clients')\n",
        "for i in range(6):\n",
        "  client_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "      emnist_train.client_ids[i]) #Data distribution to clients\n",
        "  plot_data = collections.defaultdict(list)\n",
        "  for example in client_dataset:\n",
        "    # Append counts individually per label to make plots\n",
        "    label = example['label'].numpy()\n",
        "    plot_data[label].append(label)\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.title('Client {}'.format(i))\n",
        "  for j in range(10):\n",
        "    plt.hist(\n",
        "        plot_data[j],\n",
        "        density=False,\n",
        "        bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gllJhVnzBLq"
      },
      "source": [
        "Each client has different dataset. Therefore, mean of images will differ from each other. This cell illustrated the difference between client datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqAxLKcOXXVU"
      },
      "source": [
        "# Each client has different mean images, meaning each client will be nudging\n",
        "# the model in their own directions locally.\n",
        "\n",
        "for i in range(5):\n",
        "  client_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "      emnist_train.client_ids[i])\n",
        "  plot_data = collections.defaultdict(list)\n",
        "  for example in client_dataset:\n",
        "    plot_data[example['label'].numpy()].append(example['pixels'].numpy())\n",
        "  f = plt.figure(i, figsize=(12, 5))\n",
        "  f.suptitle(\"Client #{}'s Mean Image Per Label\".format(i))\n",
        "  for j in range(10):\n",
        "    mean_img = np.mean(plot_data[j], 0)\n",
        "    plt.subplot(2, 5, j+1)\n",
        "    plt.imshow(mean_img.reshape((28, 28)))\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTqw9UPMzZUh"
      },
      "source": [
        "## 4. Data preperation\n",
        "Each image reshaped into 1 x 784 elements vector. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQkw8UzeXXH4"
      },
      "source": [
        "NUM_CLIENTS = 10\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 20\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER= 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(element['pixels'], [-1, 784]),\n",
        "        y=tf.reshape(element['label'], [-1, 1]))\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSyJsnE1XplL"
      },
      "source": [
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgEiGSbZXpaq"
      },
      "source": [
        "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "\n",
        "print('Number of client datasets: {l}'.format(l=len(federated_train_data)))\n",
        "print('First dataset: {d}'.format(d=federated_train_data[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICxu5FwaX_e-"
      },
      "source": [
        "def create_keras_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Input(shape=(784,)),\n",
        "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV6nLI8wX_kg"
      },
      "source": [
        "def model_fn():\n",
        "  # We _must_ create a new model here, and _not_ capture it from an external\n",
        "  # scope. TFF will call this within different graph contexts.\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBnzhXhsX_iR"
      },
      "source": [
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0])\n",
        "example_element = next(iter(example_dataset))\n",
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_dataset)))\n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMP3SDJXX_c4"
      },
      "source": [
        "str(iterative_process.initialize.type_signature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW5aNGPfYT62"
      },
      "source": [
        "state = iterative_process.initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFGTkAluYT9u"
      },
      "source": [
        "state, metrics = iterative_process.next(state, federated_train_data)\n",
        "print('round  1, metrics={}'.format(metrics))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q6uEEihYT4N"
      },
      "source": [
        "NUM_ROUNDS = 11\n",
        "for round_num in range(2, NUM_ROUNDS):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xO2vgy-YtG2"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "logdir = \"/tmp/logs/scalars/training/\"\n",
        "summary_writer = tf.summary.create_file_writer(logdir)\n",
        "state = iterative_process.initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGMi5stYYtLz"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "with summary_writer.as_default():\n",
        "  for round_num in range(1, NUM_ROUNDS):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    for name, value in metrics['train'].items():\n",
        "      tf.summary.scalar(name, value, step=round_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYxvxfw2YtJq"
      },
      "source": [
        "%tensorboard --logdir /tmp/logs/scalars/ --port=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjEYJ0IuYtA2"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "# Run this this cell to clean your directory of old output for future graphs from this directory.\n",
        "!rm -R /tmp/logs/scalars/*"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}